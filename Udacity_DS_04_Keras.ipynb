{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "#Create the Sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "# X has shape (num_rows, num_cols), where the training data are stored\n",
    "# as row vectors\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "\n",
    "# y must have an output vector for each input vector\n",
    "y = np.array([[0], [0], [0], [1]], dtype=np.float32)\n",
    "\n",
    "# Create the Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Layer - Add an input layer of 32 nodes with the same input shape as\n",
    "# the training samples in X\n",
    "model.add(Dense(32, input_dim=X.shape[1]))\n",
    "\n",
    "# Add a softmax activation layer\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# 2nd Layer - Add a fully connected output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Add a sigmoid activation layer\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 129\n",
      "Trainable params: 129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksatola/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are passing a target array of shape (4, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-e611094a6613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    951\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    805\u001b[0m                 \u001b[0;31m# using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m                 check_loss_and_target_compatibility(\n\u001b[0;32m--> 807\u001b[0;31m                     y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m    808\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    270\u001b[0m                 raise ValueError(\n\u001b[1;32m    271\u001b[0m                     \u001b[0;34m'You are passing a target array of shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                     \u001b[0;34m' while using as loss `categorical_crossentropy`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m                     \u001b[0;34m'`categorical_crossentropy` expects '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                     \u001b[0;34m'targets to be binary matrices (1s and 0s) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are passing a target array of shape (4, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets."
     ]
    }
   ],
   "source": [
    "model.fit(X, y, nb_epoch=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If evaluating from data tensors, you should specify the `steps` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-34717fd9598c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m             raise ValueError('If evaluating from data tensors, '\n\u001b[0m\u001b[1;32m   1094\u001b[0m                              \u001b[0;34m'you should specify the `steps` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m                              'argument.')\n",
      "\u001b[0;31mValueError\u001b[0m: If evaluating from data tensors, you should specify the `steps` argument."
     ]
    }
   ],
   "source": [
    "model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a simple multi-layer feedforward neural network to solve the XOR problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 162\n",
      "Trainable params: 162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksatola/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:33: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n",
      "\n",
      "Accuracy:  0.5\n",
      "\n",
      "Predictions:\n",
      "[[0.5850998  0.0023841 ]\n",
      " [0.00161177 0.48251843]\n",
      " [0.99994457 0.99540734]\n",
      " [0.99587387 0.9998808 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "tf.control_flow_ops = tf\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Our data\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]]).astype('float32')\n",
    "y = np.array([[0],[1],[1],[0]]).astype('float32')\n",
    "\n",
    "# Initial Setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "\n",
    "# One-hot encoding the output\n",
    "y = np_utils.to_categorical(y)\n",
    "\n",
    "# Building the model\n",
    "xor = Sequential()\n",
    "xor.add(Dense(32, input_dim=2))\n",
    "xor.add(Activation(\"tanh\"))\n",
    "xor.add(Dense(2))\n",
    "xor.add(Activation(\"sigmoid\"))\n",
    "\n",
    "xor.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics = ['accuracy'])\n",
    "\n",
    "# Uncomment this line to print the model architecture\n",
    "xor.summary()\n",
    "\n",
    "# Fitting the model\n",
    "history = xor.fit(X, y, nb_epoch=1000, verbose=0)\n",
    "\n",
    "# Scoring the model\n",
    "score = xor.evaluate(X, y)\n",
    "print(\"\\nAccuracy: \", score[-1])\n",
    "\n",
    "# Checking the predictions\n",
    "print(\"\\nPredictions:\")\n",
    "print(xor.predict_proba(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve the model to at least 75% of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 162\n",
      "Trainable params: 162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksatola/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:18: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.7046 - acc: 0.5000\n",
      "Epoch 2/80\n",
      "4/4 [==============================] - 0s 629us/step - loss: 0.7042 - acc: 0.2500\n",
      "Epoch 3/80\n",
      "4/4 [==============================] - 0s 449us/step - loss: 0.7037 - acc: 0.2500\n",
      "Epoch 4/80\n",
      "4/4 [==============================] - 0s 529us/step - loss: 0.7031 - acc: 0.2500\n",
      "Epoch 5/80\n",
      "4/4 [==============================] - 0s 874us/step - loss: 0.7026 - acc: 0.2500\n",
      "Epoch 6/80\n",
      "4/4 [==============================] - 0s 569us/step - loss: 0.7021 - acc: 0.2500\n",
      "Epoch 7/80\n",
      "4/4 [==============================] - 0s 482us/step - loss: 0.7015 - acc: 0.2500\n",
      "Epoch 8/80\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7011 - acc: 0.2500\n",
      "Epoch 9/80\n",
      "4/4 [==============================] - 0s 879us/step - loss: 0.7006 - acc: 0.2500\n",
      "Epoch 10/80\n",
      "4/4 [==============================] - 0s 403us/step - loss: 0.7001 - acc: 0.2500\n",
      "Epoch 11/80\n",
      "4/4 [==============================] - 0s 689us/step - loss: 0.6997 - acc: 0.2500\n",
      "Epoch 12/80\n",
      "4/4 [==============================] - 0s 583us/step - loss: 0.6992 - acc: 0.5000\n",
      "Epoch 13/80\n",
      "4/4 [==============================] - 0s 487us/step - loss: 0.6988 - acc: 0.5000\n",
      "Epoch 14/80\n",
      "4/4 [==============================] - 0s 483us/step - loss: 0.6984 - acc: 0.5000\n",
      "Epoch 15/80\n",
      "4/4 [==============================] - 0s 589us/step - loss: 0.6980 - acc: 0.5000\n",
      "Epoch 16/80\n",
      "4/4 [==============================] - 0s 537us/step - loss: 0.6976 - acc: 0.5000\n",
      "Epoch 17/80\n",
      "4/4 [==============================] - 0s 707us/step - loss: 0.6972 - acc: 0.5000\n",
      "Epoch 18/80\n",
      "4/4 [==============================] - 0s 558us/step - loss: 0.6969 - acc: 0.5000\n",
      "Epoch 19/80\n",
      "4/4 [==============================] - 0s 474us/step - loss: 0.6965 - acc: 0.5000\n",
      "Epoch 20/80\n",
      "4/4 [==============================] - 0s 494us/step - loss: 0.6962 - acc: 0.5000\n",
      "Epoch 21/80\n",
      "4/4 [==============================] - 0s 470us/step - loss: 0.6958 - acc: 0.5000\n",
      "Epoch 22/80\n",
      "4/4 [==============================] - 0s 514us/step - loss: 0.6955 - acc: 0.5000\n",
      "Epoch 23/80\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6952 - acc: 0.5000\n",
      "Epoch 24/80\n",
      "4/4 [==============================] - 0s 492us/step - loss: 0.6949 - acc: 0.5000\n",
      "Epoch 25/80\n",
      "4/4 [==============================] - 0s 621us/step - loss: 0.6946 - acc: 0.5000\n",
      "Epoch 26/80\n",
      "4/4 [==============================] - 0s 538us/step - loss: 0.6943 - acc: 0.5000\n",
      "Epoch 27/80\n",
      "4/4 [==============================] - 0s 503us/step - loss: 0.6940 - acc: 0.5000\n",
      "Epoch 28/80\n",
      "4/4 [==============================] - 0s 376us/step - loss: 0.6937 - acc: 0.5000\n",
      "Epoch 29/80\n",
      "4/4 [==============================] - 0s 697us/step - loss: 0.6934 - acc: 0.5000\n",
      "Epoch 30/80\n",
      "4/4 [==============================] - 0s 549us/step - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 31/80\n",
      "4/4 [==============================] - 0s 599us/step - loss: 0.6929 - acc: 0.5000\n",
      "Epoch 32/80\n",
      "4/4 [==============================] - 0s 535us/step - loss: 0.6927 - acc: 0.5000\n",
      "Epoch 33/80\n",
      "4/4 [==============================] - 0s 493us/step - loss: 0.6924 - acc: 0.5000\n",
      "Epoch 34/80\n",
      "4/4 [==============================] - 0s 697us/step - loss: 0.6922 - acc: 0.5000\n",
      "Epoch 35/80\n",
      "4/4 [==============================] - 0s 555us/step - loss: 0.6919 - acc: 0.5000\n",
      "Epoch 36/80\n",
      "4/4 [==============================] - 0s 648us/step - loss: 0.6917 - acc: 0.5000\n",
      "Epoch 37/80\n",
      "4/4 [==============================] - 0s 537us/step - loss: 0.6914 - acc: 0.5000\n",
      "Epoch 38/80\n",
      "4/4 [==============================] - 0s 686us/step - loss: 0.6912 - acc: 0.5000\n",
      "Epoch 39/80\n",
      "4/4 [==============================] - 0s 545us/step - loss: 0.6910 - acc: 0.5000\n",
      "Epoch 40/80\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.6907 - acc: 0.5000\n",
      "Epoch 41/80\n",
      "4/4 [==============================] - 0s 795us/step - loss: 0.6905 - acc: 0.5000\n",
      "Epoch 42/80\n",
      "4/4 [==============================] - 0s 497us/step - loss: 0.6903 - acc: 0.5000\n",
      "Epoch 43/80\n",
      "4/4 [==============================] - 0s 573us/step - loss: 0.6901 - acc: 0.5000\n",
      "Epoch 44/80\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6899 - acc: 0.5000\n",
      "Epoch 45/80\n",
      "4/4 [==============================] - 0s 590us/step - loss: 0.6896 - acc: 0.5000\n",
      "Epoch 46/80\n",
      "4/4 [==============================] - 0s 468us/step - loss: 0.6894 - acc: 0.5000\n",
      "Epoch 47/80\n",
      "4/4 [==============================] - 0s 520us/step - loss: 0.6892 - acc: 0.5000\n",
      "Epoch 48/80\n",
      "4/4 [==============================] - 0s 473us/step - loss: 0.6890 - acc: 0.7500\n",
      "Epoch 49/80\n",
      "4/4 [==============================] - 0s 408us/step - loss: 0.6888 - acc: 0.7500\n",
      "Epoch 50/80\n",
      "4/4 [==============================] - 0s 531us/step - loss: 0.6886 - acc: 0.7500\n",
      "Epoch 51/80\n",
      "4/4 [==============================] - 0s 447us/step - loss: 0.6884 - acc: 0.7500\n",
      "Epoch 52/80\n",
      "4/4 [==============================] - 0s 465us/step - loss: 0.6881 - acc: 0.7500\n",
      "Epoch 53/80\n",
      "4/4 [==============================] - 0s 799us/step - loss: 0.6879 - acc: 0.7500\n",
      "Epoch 54/80\n",
      "4/4 [==============================] - 0s 869us/step - loss: 0.6877 - acc: 0.7500\n",
      "Epoch 55/80\n",
      "4/4 [==============================] - 0s 690us/step - loss: 0.6875 - acc: 0.7500\n",
      "Epoch 56/80\n",
      "4/4 [==============================] - 0s 875us/step - loss: 0.6873 - acc: 0.7500\n",
      "Epoch 57/80\n",
      "4/4 [==============================] - 0s 542us/step - loss: 0.6870 - acc: 0.7500\n",
      "Epoch 58/80\n",
      "4/4 [==============================] - 0s 401us/step - loss: 0.6868 - acc: 0.7500\n",
      "Epoch 59/80\n",
      "4/4 [==============================] - 0s 540us/step - loss: 0.6866 - acc: 0.7500\n",
      "Epoch 60/80\n",
      "4/4 [==============================] - 0s 833us/step - loss: 0.6863 - acc: 0.7500\n",
      "Epoch 61/80\n",
      "4/4 [==============================] - 0s 955us/step - loss: 0.6861 - acc: 0.7500\n",
      "Epoch 62/80\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6859 - acc: 0.7500\n",
      "Epoch 63/80\n",
      "4/4 [==============================] - 0s 871us/step - loss: 0.6856 - acc: 0.7500\n",
      "Epoch 64/80\n",
      "4/4 [==============================] - 0s 443us/step - loss: 0.6854 - acc: 0.7500\n",
      "Epoch 65/80\n",
      "4/4 [==============================] - 0s 668us/step - loss: 0.6852 - acc: 0.7500\n",
      "Epoch 66/80\n",
      "4/4 [==============================] - 0s 429us/step - loss: 0.6849 - acc: 0.7500\n",
      "Epoch 67/80\n",
      "4/4 [==============================] - 0s 682us/step - loss: 0.6847 - acc: 0.7500\n",
      "Epoch 68/80\n",
      "4/4 [==============================] - 0s 625us/step - loss: 0.6844 - acc: 0.7500\n",
      "Epoch 69/80\n",
      "4/4 [==============================] - 0s 799us/step - loss: 0.6842 - acc: 0.7500\n",
      "Epoch 70/80\n",
      "4/4 [==============================] - 0s 691us/step - loss: 0.6839 - acc: 0.7500\n",
      "Epoch 71/80\n",
      "4/4 [==============================] - 0s 647us/step - loss: 0.6836 - acc: 0.7500\n",
      "Epoch 72/80\n",
      "4/4 [==============================] - 0s 507us/step - loss: 0.6834 - acc: 0.7500\n",
      "Epoch 73/80\n",
      "4/4 [==============================] - 0s 689us/step - loss: 0.6831 - acc: 0.7500\n",
      "Epoch 74/80\n",
      "4/4 [==============================] - 0s 742us/step - loss: 0.6828 - acc: 0.7500\n",
      "Epoch 75/80\n",
      "4/4 [==============================] - 0s 588us/step - loss: 0.6825 - acc: 0.7500\n",
      "Epoch 76/80\n",
      "4/4 [==============================] - 0s 547us/step - loss: 0.6823 - acc: 0.7500\n",
      "Epoch 77/80\n",
      "4/4 [==============================] - 0s 558us/step - loss: 0.6820 - acc: 0.7500\n",
      "Epoch 78/80\n",
      "4/4 [==============================] - 0s 615us/step - loss: 0.6817 - acc: 0.7500\n",
      "Epoch 79/80\n",
      "4/4 [==============================] - 0s 423us/step - loss: 0.6814 - acc: 0.7500\n",
      "Epoch 80/80\n",
      "4/4 [==============================] - 0s 512us/step - loss: 0.6811 - acc: 0.7500\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "\n",
      "Accuracy:  0.75\n",
      "\n",
      "Predictions:\n",
      "[[0.5018178  0.44622257]\n",
      " [0.46447352 0.505236  ]\n",
      " [0.520382   0.52760285]\n",
      " [0.5104573  0.5687734 ]]\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Building the model\n",
    "xor = Sequential()\n",
    "xor.add(Dense(32, input_dim=2))\n",
    "xor.add(Activation(\"tanh\"))\n",
    "xor.add(Dense(2))\n",
    "xor.add(Activation(\"sigmoid\"))\n",
    "\n",
    "xor.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics = ['accuracy'])\n",
    "\n",
    "# Uncomment this line to print the model architecture\n",
    "xor.summary()\n",
    "\n",
    "## IMPROVEMENT: changed number epochs to 80\n",
    "# Fitting the model\n",
    "history = xor.fit(X, y, nb_epoch=80, verbose=1)\n",
    "\n",
    "# Scoring the model\n",
    "score = xor.evaluate(X, y)\n",
    "print(\"\\nAccuracy: \", score[-1])\n",
    "\n",
    "# Checking the predictions\n",
    "print(\"\\nPredictions:\")\n",
    "print(xor.predict_proba(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See: [Lab: Student Admissions in Keras](Udacity_DS_04_Keras.ipynb/StudentAdmissionsKeras.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Project: Using Keras to analyze IMDB Movie Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See: [Analyzing IMDB Data in Keras](Udacity_DS_04_Keras.ipynb/IMDB_In_Keras.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
